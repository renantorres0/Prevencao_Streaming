# -*- coding: utf-8 -*-
"""RID214533_Desafio06.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TQjW1dFkNtKABWOP_aFqVvniy4efG0j5

# Etapa 01: Análise Exploratória dos Dados (Data Understanding)
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay, classification_report
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('streaming_data.csv')

print(df.describe())
print(df.info())
print(df.isna().sum())

df.hist(figsize=(15, 12))
plt.show()

sns.countplot(x='Churned', data=df)
plt.show()

"""# Etapa 02: Tratamento dos Dados (Data Preparation)"""

df['Time_on_platform'] = df['Time_on_platform'].fillna(0)
df['Num_streaming_services'] = df['Num_streaming_services'].fillna(0)
df['Churned'] = df['Churned'].fillna(0)
df['Avg_rating'] = df['Avg_rating'].fillna(0)
df['Devices_connected'] = df['Devices_connected'].fillna(0)

df.dropna(subset=['Gender', 'Subscription_type', 'Age'], inplace=True)

df['Churned'] = df['Churned'].replace({0: 'No', 1: 'Yes'})

df['Time_on_platform'] = df['Time_on_platform'].astype(int)
df['Num_streaming_services'] = df['Num_streaming_services'].astype(int)
df['Avg_rating'] = df['Avg_rating'].astype(int)
df['Devices_connected'] = df['Devices_connected'].astype(int)

print(df.head())

"""# Etapa 03: Modelagem dos Dados - Regressão Logística"""

X = df.drop('Churned', axis=1)
y = df['Churned']

colunas_nao_numericas = X.select_dtypes(include=['object']).columns

le = LabelEncoder()
for coluna in colunas_nao_numericas:
  X[coluna] = le.fit_transform(X[coluna])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=5000, class_weight='balanced')
model.fit(X_train, y_train)
print(f"Coeficientes: {model.coef_}")
print(f"Intercepto: {model.intercept_}")

y_pred = model.predict(X_test)

ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
plt.show()

print(classification_report(y_test, y_pred))

"""# Etapa 04: Modelagem dos Dados - Tunning"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

param_grid = {
    'C': [0.1, 1, 10, 100, 1000],
    'penalty': ['l1','l2'],
    'solver': ['liblinear']
}

grid_search = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_scaled, y_train)

best_model = grid_search.best_estimator_
print(f"Melhor modelo: {best_model}")

y_pred_proba = best_model.predict_proba(X_test_scaled)
print(y_pred_proba)

print(X_train.isnull().sum())
print(X_test.isnull().sum())

# Avaliação do modelo
y_pred = best_model.predict(X_test_scaled)

ConfusionMatrixDisplay.from_estimator(best_model, X_test_scaled, y_test)
plt.show()

print(classification_report(y_test, y_pred, zero_division=0))

"""# Etapa 05: Modelagem de Dados - Random Forest"""

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test)
plt.show()

print(classification_report(y_test, y_pred_rf))